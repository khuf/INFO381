{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prejudice removal\n",
    "\n",
    "**Uses the Prejudice removal in-processing algorithm from the AIF360 toolkit. Adds a discrimination-aware regularization term to the learning objective** \n",
    "\n",
    "See https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.inprocessing.PrejudiceRemover.html <br />\n",
    "See http://aif360.mybluemix.net/resources#guidance for guidance on metrics and mitigation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../datasets'))\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from common_utils import compute_metrics\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "\n",
    "# Import employment dataset \n",
    "from EmploymentDataset import EmploymentDataset\n",
    "from util import preprocess_employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'Sex': 1}]\n",
    "unprivileged_groups = [{'Sex': 0}]\n",
    "\n",
    "# Fairness penalty paramenters\n",
    "eta = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 10.0, 15.0, 20.0, 30.0, 40.0, 50.0, 100.0,\n",
    "                         150.0, 200.0, 250.0, 300.0] \n",
    "\n",
    "prejudice_remover = PrejudiceRemover(eta=10, sensitive_attr = 'Sex', class_attr='EmploymentStatus')\n",
    "prejudice_no_penalty = PrejudiceRemover(sensitive_attr = 'Sex', class_attr='EmploymentStatus')\n",
    " \n",
    "# Import the dataset\n",
    "dataset_orig = preprocess_employment(['Sex'])\n",
    "\n",
    "# Split dataset 70/30\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.095891\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.094418\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.095891\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.094418\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.prejudice_remover.PrejudiceRemover at 0x7fa5c6439710>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "prejudice_no_penalty.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the unconstrained model to test data\n",
    "dataset_train_transformed_plain = prejudice_no_penalty.predict(dataset_orig_train)\n",
    "dataset_test_transformed_plain = prejudice_no_penalty.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## No fairness contraints - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Model without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.025344\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.016847\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.815274\n",
      "Test set: Balanced classification accuracy = 0.660981\n",
      "Test set: Disparate impact = 0.981027\n",
      "Test set: Equal opportunity difference = -0.020949\n",
      "Test set: Average odds difference = 0.054591\n",
      "Test set: Theil_index = 0.076198\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from model without debiasing\n",
    "display(Markdown(\"## No fairness contraints - dataset metrics\"))\n",
    "display(Markdown(\"#### Model without debiasing - dataset metrics\"))\n",
    "metric_dataset_prejudiceremover_train = BinaryLabelDatasetMetric(dataset_train_transformed_plain, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_prejudiceremover_train.mean_difference())\n",
    "\n",
    "metric_dataset_prejudiceremover_test = BinaryLabelDatasetMetric(dataset_test_transformed_plain, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_prejudiceremover_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Model without debiasing - classification metrics\"))\n",
    "classified_metric_prejudiceremover_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_test_transformed_plain,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_prejudiceremover_test.accuracy())\n",
    "TPR = classified_metric_prejudiceremover_test.true_positive_rate()\n",
    "TNR = classified_metric_prejudiceremover_test.true_negative_rate()\n",
    "bal_acc_predjudiceremover_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_predjudiceremover_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_prejudiceremover_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_prejudiceremover_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_prejudiceremover_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_prejudiceremover_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.prejudice_remover.PrejudiceRemover at 0x7fa5c6439780>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prejudice_remover.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the prejudice remover model to test data\n",
    "dataset_train_transformed = prejudice_remover.predict(dataset_orig_train)\n",
    "dataset_test_transformed = prejudice_remover.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## No fairness contraints - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Model without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.025344\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.016847\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model without debiasing - classification metrics (test set)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.815274\n",
      "Test set: Balanced classification accuracy = 0.660981\n",
      "Test set: Disparate impact = 0.981027\n",
      "Test set: Equal opportunity difference = -0.020949\n",
      "Test set: Average odds difference = 0.054591\n",
      "Test set: Theil_index = 0.076198\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## With fairness constraints - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Model with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.015708\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.005376\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model with biasing - classification metrics (test set)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.815890\n",
      "Test set: Balanced classification accuracy = 0.653882\n",
      "Test set: Disparate impact = 0.993981\n",
      "Test set: Equal opportunity difference = -0.012431\n",
      "Test set: Average odds difference = 0.066897\n",
      "Test set: Theil_index = 0.070934\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## No fairness contraints - dataset metrics\"))\n",
    "# Metrics for the dataset from model without debiasing\n",
    "display(Markdown(\"#### Model without debiasing - dataset metrics\"))\n",
    "metric_dataset_prejudiceremover_train = BinaryLabelDatasetMetric(dataset_train_transformed_plain, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_prejudiceremover_train.mean_difference())\n",
    "\n",
    "metric_dataset_prejudiceremover_test = BinaryLabelDatasetMetric(dataset_test_transformed_plain, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_prejudiceremover_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Model without debiasing - classification metrics (test set)\"))\n",
    "classified_metric_prejudiceremover_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_test_transformed_plain,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_prejudiceremover_test.accuracy())\n",
    "TPR = classified_metric_prejudiceremover_test.true_positive_rate()\n",
    "TNR = classified_metric_prejudiceremover_test.true_negative_rate()\n",
    "bal_acc_predjudiceremover_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_predjudiceremover_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_prejudiceremover_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_prejudiceremover_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_prejudiceremover_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_prejudiceremover_test.theil_index())\n",
    "\n",
    "###### Debiasing begins here ############\n",
    "\n",
    "\n",
    "display(Markdown(\"## With fairness constraints - dataset metrics\"))\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model with debiasing - dataset metrics\"))\n",
    "metric_dataset_prejudiceremover_train = BinaryLabelDatasetMetric(dataset_train_transformed, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_prejudiceremover_train.mean_difference())\n",
    "\n",
    "metric_dataset_prejudiceremover_test = BinaryLabelDatasetMetric(dataset_test_transformed, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_prejudiceremover_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Model with biasing - classification metrics (test set)\"))\n",
    "classified_metric_prejudiceremover_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_test_transformed,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_prejudiceremover_test.accuracy())\n",
    "TPR = classified_metric_prejudiceremover_test.true_positive_rate()\n",
    "TNR = classified_metric_prejudiceremover_test.true_negative_rate()\n",
    "bal_acc_predjudiceremover_test = 0.5*(TPR+TNR)\n",
    "print(\"Balanced classification accuracy = %f\" % bal_acc_predjudiceremover_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_prejudiceremover_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_prejudiceremover_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_prejudiceremover_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_prejudiceremover_test.theil_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
